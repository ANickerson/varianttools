#!/usr/bin/env python2.7
#
# $File: vtools_report $
# $LastChangedDate$
# $Rev$
#
# This file is part of variant_tools, a software application to annotate,
# summarize, and filter variants for next-gen sequencing ananlysis.
# Please visit http://varianttools.sourceforge.net for details.
#
# Copyright (C) 2011 Bo Peng (bpeng@mdanderson.org)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#

import sys, os
import argparse
import subprocess
import logging

#
# These functions are utility functions used by all reports
#
def addVerbosityArg(parser):
    parser.add_argument('-v', '--verbosity', default='1', choices=['0','1','2'],
        help='''Output error and warning (0), info (1) and debug (2) information
            of vtools and vtools_report. Debug information are always recorded
            in project and vtools_report log files.''')

# global logger object, which will be set by getLogger() when the script
# is executed. 
verbosity = '1'
logger = None

def getLogger():
    # create a logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    # output to standard output
    cout = logging.StreamHandler()
    levels = {
        None: logging.INFO,
        '0': logging.ERROR,
        '1': logging.INFO,
        '2': logging.DEBUG
        }
    #
    cout.setLevel(levels[verbosity])
    cout.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
    logger.addHandler(cout)
    # output to a log file vtools_report.log
    ch = logging.FileHandler('vtools_report.log', mode='a')
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(logging.Formatter('%(asctime)s: %(levelname)s: %(message)s'))
    logger.addHandler(ch)
    return logger


def getoutput(cmd):
    # add -v option if unspecified
    if True not in [x.startswith('-v') for x in cmd]:
        cmd.append('-v{}'.format(verbosity))
    # call vtools and return its output
    logger.info('Running: ' + ' '.join([x if (x.isalnum() or x.startswith('-')) else '"' + x.replace('"', '\"') + '"' for x in cmd]))
    # '.' is added to $PATH so that command (vtools) that is in the current directory
    # can be executed.
    return subprocess.check_output(cmd, env={'PATH': os.pathsep.join(['.', os.environ['PATH']])}).strip().decode()

def outputToFile(cmd, filename):
    # execute a command and send its output to a file
    if True not in [x.startswith('-v') for x in cmd]:
        cmd.append('-v{}'.format(verbosity))
    # call vtools and return its output
    logger.info('Running: ' + ' '.join([x if (x.isalnum() or x.startswith('-')) else '"' + x.replace('"', '\"') + '"' for x in cmd]))
    # '.' is added to $PATH so that command (vtools) that is in the current directory
    # can be executed.
    with open(filename, 'w') as output:
        subprocess.call(cmd, stdout=output, env={'PATH': os.pathsep.join(['.', os.environ['PATH']])})

def RdeviceFromFilename(filename):
    # guess the device used to plot R plot from filename
    basename, ext = os.path.splitext(filename)
    # default
    device = 'postscript'
    params = ''
    try:
        # functions are not available in, for example, R 2.6.2
        if ext.lower() == '.pdf':
            device = 'pdf'
        elif ext.lower() == '.png':
            device = 'png'
            params = ', width=800, height=600'
        elif ext.lower() == '.bmp':
            device = 'bmp'
            params = ', width=800, height=600'
        elif ext.lower() in ['.jpg', '.jpeg']:
            device = 'jpeg'
            params = ', width=800, height=600'
        elif ext.lower() in ['.tif', '.tiff']:
            device = 'tiff'
            params = ', width=800, height=600'
        elif ext.lower() == '.eps':
            device = 'postscript'
    except Exception, e:
        logger.warning('Can not determine which device to use to save file {}. A postscript driver is used: {}'.format(name, e))
        device = 'postscript'
    return '{}("{}" {})'.format(device, filename, params)

def executeRScript(script):
    # write script to log file for debugging and customization purposes
    logger.info('Running R script (complete script available in vtools_report.log)'.format(script))
    logger.debug(script)
    # start R
    process = subprocess.Popen(['R', '--slave', '--vanilla'], 
        stdin=subprocess.PIPE, stderr=subprocess.PIPE)
    # send script and get standard output and error
    out, err = process.communicate(script)
    if err.strip():
        logger.warning(err)
    return process.wait()


#
# These functions call vtools to extract information that are needed by other
# reports.
#
def getNumOfSamples():
    logger.info('Getting number of samples')
    return int(getoutput(['vtools', 'execute', 'SELECT count(1) FROM sample']))

def getSamples(samples, group_by=[]):
    '''return a generator that returns samples group by group. To use this functions, call it like
    for group, IDs in getSamples(condi, group_by):
        # do something with group and IDs.
    '''
    output = getoutput(['vtools', 'execute', 'SELECT {} FROM sample LEFT OUTER JOIN filename ON sample.file_id = filename.file_id {} {};'\
        .format('sample_id, sample_name, {}'.format(', '.join(group_by)) if group_by else 'sample_id, sample_name',
            'WHERE {}'.format(' AND '.join(samples)) if samples else '',
            'GROUP BY {}'.format(', '.join(group_by)) if group_by else '')]).split('\n')
    # we return results batch by batch as a generator
    IDs = []
    names = []
    group = ()
    for line in output:
        fields = [x.strip() for x in line.split('\t')]
        ID = fields[0]
        name = fields[1]
        g = tuple(fields[2:])
        if group == ():
            group = g
        if g == group:
            IDs.append(ID)
            names.append(name)
        else:
            yield (group, IDs, names)
            # start a new group
            group = g
            IDs = [ID]
            names = [name]
    yield (group, IDs, names)

#
# Command trans_ratio
#
def transRatioArguments(parser):
    parser.add_argument('-n', '--num_field', required=True,
        help='''Name of the field that holds sample variant count, which is the field name for
            command 'vtools update table --from_stat "num=#(alt)"'.''')
    parser.add_argument('--group_by', nargs='*', default=[],
        help='''Output transition/transversion rate for groups of variants. e.g. --group_by 
            num for each sample variant frequency group.''')
    parser.add_argument('table', 
        help='''Variant table for which transversion/transversion mutants are counted.''')

def transRatio(args):
    #
    if args.group_by:
        print('{}\tnum_of_transition\tnum_of_transversion\tratio'.format('\t'.join(args.group_by)))
        transition = getoutput(['vtools', 'select', args.table, 
            "((ref='A' AND alt='G') OR (ref='G' AND alt='A') OR (ref='C' AND alt='T') OR (ref='T' AND alt='C'))", 
            '--output'] + args.group_by + ['sum({})'.format(args.num_field), '--group_by'] + args.group_by)
        transversion = getoutput(['vtools', 'select', args.table, 
            "((ref='A' AND alt='C') OR (ref='C' AND alt='A') OR (ref='G' AND alt='T') OR " + 
            " (ref='T' AND alt='G') OR (ref='A' AND alt='T') OR (ref='T' AND alt='A') OR " +
            " (ref='C' AND alt='G') OR (ref='G' AND alt='C'))", '--output'] + args.group_by +  
            ['sum({})'.format(args.num_field), '--group_by'] +  args.group_by)
        values = {}
        for item in transition.split('\n'):
            g, v = item.rsplit('\t', 1)
            values[g] = [v, '0']
        for item in transversion.split('\n'):
            g, v = item.rsplit('\t', 1)
            if g in values:
                values[g][1] = v
            else:
                values[g] = ['0', v]
        keys = list(values.keys())
        keys.sort()
        for k in keys:
            print('{}\t{:,}\t{:,}\t{:.5f}'.format(k, int(values[k][0]), int(values[k][1]),
                int(values[k][0])/float(values[k][1]) if int(values[k][1]) > 0 else 0))
    else:
        print('num_of_transition\tnum_of_transversion\tratio')
        transition = int(getoutput(['vtools', 'select', args.table, 
            "(ref='A' AND alt='G') OR (ref='G' AND alt='A') OR (ref='C' AND alt='T') OR (ref='T' AND alt='C')",
            '--output', 'sum({})'.format(args.num_field)]))
        transversion = int(getoutput(['vtools', 'select', args.table, 
            "(ref='A' AND alt='C') OR (ref='C' AND alt='A') OR (ref='G' AND alt='T') OR " + 
            "(ref='T' AND alt='G') OR (ref='A' AND alt='T') OR (ref='T' AND alt='A') OR " +
            "(ref='C' AND alt='G') OR (ref='G' AND alt='C')",
            '--output', 'sum({})'.format(args.num_field)]))
        print('{}\t{}\t{:.5f}'.format(transition, transversion, 
            transition / float(transversion) if transversion != 0 else 0))
    
#
# Command avg_depth
#
def avgDepthArguments(parser):
    parser.add_argument('-n', '--num_field', required=True,
        help='''Name of the field that holds sample variant count, which is the field name for
            command 'vtools update table --from_stat "num=#(alt)"'.''')
    parser.add_argument('-d', '--depth_field', required=True,
        help='''Name of the field that holds average depth of each variant, which is the field
            name for command 'vtools update table --from_stat "meanDP=avg(DP_geno)"'.''')
    parser.add_argument('--group_by', nargs='*', default=[],
        help='''Output average depth for each group, for example,
            '--group_by NUM_FIELD to output depth for each sample variant frequency (count).''')
    parser.add_argument('table',
        help='''Variant table for which average depth are calculated.''')

def avgDepth(args):
    print('{}num_of_variant\taverage_depth'.format(''.join([x+'\t' for x in args.group_by])))
    print(getoutput(['vtools', 'output', args.table] + args.group_by + 
        ['COUNT(1)', 'SUM({0}*{1})/SUM({0})'.format(args.num_field, args.depth_field)] +
        (['--group_by'] + args.group_by if args.group_by else [])))

#
# Command variant_stat
#
def variantStatArguments(parser):
    parser.add_argument('-s', '--samples', nargs='*', default=[],
        help='''Limiting variants from samples that match conditions that
            use columns shown in command 'vtools show sample' (e.g. 'aff=1',
            'filename like "MG%%"').''')
    parser.add_argument('-g', '--group_by', nargs='*', default=[],
        help='''Group samples by certain conditions such as 'aff=1'. A common
            usage is to group variants by 'filename' and 'sample_name' so that
            variant statistics are outputted for each sample.''')
    parser.add_argument('table', 
        help='''Variant table for which variant metrics are calculated.''')

def variantStat(args):
    # 1) Get samples based on the conditional parameter --samples
    #    Exit the report if there are no samples to analyze.
    print('\t'.join(list(args.group_by) + ['num_sample', 'num_snps', 'num_insertions', 'num_deletions', 
        'num_substitutions', 'min_insertion_size', 'avg_insertion_size', 'max_insertion_size',
        'min_deletion_size', 'avg_deletion_size', 'max_deletion_size']))
    for group, sample_ids, sample_names in getSamples(args.samples, args.group_by):
        if len(sample_ids) == 0:
            sys.exit('There are no available samples to analyze {}.\n'.format(('given {}'.format(args.samples)) if args.samples else ''))
        #
        # 2a) Get the counts for snps and substitutions:
        #     command: vtools select __tmp_vs "ref != '-' and alt != '-' and (length(ref) = 1 and length(alt) = 1)" --samples 'sample_id in $sample_ids' --count
        num_snps = getoutput(['vtools', 'select', args.table, "ref != '-'", "alt != '-'", "(length(ref) = 1 and length(alt) = 1)",
            '--samples', 'sample_id IN ({})'.format(','.join(sample_ids)), '--count'])
        num_substitutions = getoutput(['vtools', 'select', args.table, "ref != '-'", "alt != '-'", "(length(ref) > 1 or length(alt) > 1)",
            '--samples', 'sample_id IN ({})'.format(','.join(sample_ids)), '--count'])
        #
        # 2b) Get the metrics to characterize the insertions
        #     command: vtools select variant "ref = '-'" --samples 'sample_id IN $sample_ids' --output 'count(alt)', 'avg(length(alt))' 'min(length(alt))' 'max(length(alt))'
        num_insertions, avg_insertion_size, min_insertion_size, max_insertion_size = getoutput(
            ['vtools', 'select', args.table, "ref='-'", '--samples', 'sample_id IN ({})'.format(','.join(sample_ids)),
            '--output', 'count(alt)', 'avg(length(alt))', 'min(length(alt))', 'max(length(alt))']).split('\t')
        #        
        # 2c) Get the metrics to characterize the deletions
        #     command: vtools select variant "alt = '-'" --samples 'sample_id IN $sample_ids' --output 'count(ref)', 'avg(length(ref))' 'min(length(ref))' 'max(length(ref))'       
        num_deletions, avg_deletion_size, min_deletion_size, max_deletion_size = getoutput(
            ['vtools', 'select', args.table, "alt='-'", '--samples', 'sample_id IN ({})'.format(','.join(sample_ids)),
            '--output', 'count(ref)', 'avg(length(ref))', 'min(length(ref))', 'max(length(ref))']).split('\t')     
        #
        print('\t'.join(list(group) + [str(len(sample_ids)), num_snps, num_insertions, num_deletions,
            num_substitutions, min_insertion_size, avg_insertion_size, max_insertion_size,
            min_deletion_size, avg_deletion_size, max_deletion_size]))
    

#
# command discordance_rate
#
def discordanceRateArguments(parser):
    parser.add_argument('-s', '--samples', nargs='*', default=[],
        help='''Limiting variants from samples that match conditions that
            use columns shown in command 'vtools show sample' (e.g. 'aff=1',
            'filename like "MG%%"').''')
    parser.add_argument('--genotypes', nargs='*', default=[],
        help='''Limiting genotypes from samples that match conditions that
            involves genotype fields (e.g. filter by quality score, with fields
            shown in command 'vtools show genotypes'). If a variant is filtered
            for one sample but not another, it will be included if runtime option
            $treat_missing_as_wildtype is set to True, and discarded otherwise.''')
    
def discordanceRate(args):
    for grp, sample_ids, sample_names in getSamples(args.samples):
        print('\t'.join(sample_names))
        # get list of variant for each sample
        rates = []
        treat_missing_as_wildtype = getoutput(['vtools', 'show', 'runtime_option', 'treat_missing_as_wildtype'])
        for i, (id_i, name_i) in enumerate(zip(sample_ids, sample_names)):
            rates.append([0] * len(sample_ids))
            output_items = []
            var_i = {}
            for line in getoutput(['vtools', 'execute', 'SELECT variant_id, GT FROM genotype.genotype_{} {}'.format(id_i,
                ('WHERE ' + ','.join(['({})'.format(x) for x in args.genotypes])) if args.genotypes else '')]).split('\n'):
                var, gt = line.split()
                var_i[var] = gt
            for j, (id_j, name_j) in enumerate(zip(sample_ids, sample_names)):
                if i > j:
                    output_items.append('{:.5f}'.format(float(rates[j][i][0]) / rates[j][i][1]))
                elif i == j:
                    output_items.append('0/{0}'.format(len(var_i)))
                else:
                    var_j = {}
                    for line in getoutput(['vtools', 'execute', 'SELECT variant_id, GT FROM genotype.genotype_{} {}'.format(id_j,
                        ('WHERE ' + ','.join(['({})'.format(x) for x in args.genotypes])) if args.genotypes else '')]).split('\n'):
                        var, gt = line.split()
                        var_j[var] = gt
                    if treat_missing_as_wildtype == 'False':
                        # find variant that exist in both samples
                        exist_in_both = [item for item in var_i.keys() if item in var_j]
                        # find variant that has different variant
                        differ_in_two = [item for item in exist_in_both if var_i[item] != var_j[item]]
                        rates[i][j] = (len(differ_in_two), len(exist_in_both))
                    else:
                        exist_in_any = set(var_i.keys()) | set(var_j.keys())
                        # remove 0 items to facilitate search
                        var_i = {x:y for x,y in var_i.items() if y != 0}
                        var_j = {x:y for x,y in var_j.items() if y != 0}
                        #
                        differ_in_two = [item for item in exist_in_any if (not item in var_i) \
                            or (not item in var_j) or (var_i[item] != var_j[item])]
                        rates[i][j] = (len(differ_in_two), len(exist_in_any))
                    output_items.append('{}/{}'.format(rates[i][j][0], rates[i][j][1]))
            print('\t'.join(output_items))

#
# command plot_fields
#
def plotFieldsArguments(parser):
    parser.add_argument('fields', nargs='+', help='A list of fields that will be outputted.')
    parser.add_argument('--variants', default='variant', metavar='TABLE',
        help='''Limit value of fields to variant in specified variant table. Default to all variants.''')
    parser.add_argument('--data_file', default='plot_fields.dat',
        help='''Name of the output data file.''')
    hist = parser.add_argument_group('Draw histogram')
    hist.add_argument('--hist',
        help='''File name of the outputted figure, which can have type PDF,
            EPS, or JPG. Multiple files might be produced if more than one figure
            is produced (e.g. MyFig1.pdf, MyFig2.pdf if MyFig.pdf is specified).''')
    hist.add_argument('--title',
        help='''Title of the histogram. '$FIELD' in the title will be replaced
            by name of the field.''')
    #hist.add_argument('--group_by',
    #    help='''A field that will be used to group others. The histogram of this
    #        field will not be plotted.''')
    #
    #cust = parser.add_argument_group('Draw plot using user-specified script.')
    #cust.add_argument('--script', nargs='+', metavar=('SCRIPT', 'OPT'), 
    #    help='''Path to a user-provided script, which
    #        will be called by 'Rscript $script $name' where $name is the data file
    #        generated by this command. Additional arguments of this script will be passed
    #        directly the script.''')
    
def plotFields(args):
    # step 1, call vtools output
    logger.info('Generating data file {}'.format(args.data_file))
    outputToFile(['vtools', 'output', args.variants] + args.fields,
        filename=args.data_file)
    if args.hist is not None:
        # Here we generate the data file (which can be big),
        # create a script dynamically, and pump it to a R process.
        #
        # note the use of {{, }} for real {}
        script='''
            data <- read.table("{0.data_file}", header=FALSE, col.names=c({1}))
            {2} # start device
            for (i in 1 : ncol(data)) {{
                tryCatch( {{
                    hist(data[,i])
                }}, error = function(err) {{
                    print(paste('Failed to generate histogram for column ', colnames(data)[i], ': ', err))
                }})
            }}
            dev.off()
            '''.format(args,
                ', '.join(['"{}"'.format(x) for x in args.fields]),
                RdeviceFromFilename(args.hist))
        # 
        # call the script
        executeRScript(script)
    
#
# command plot_geno_fields
#
def plotGenoFieldsArguments(parser):
    parser.add_argument('fields', nargs='+', help='A list of genotype fields that will be outputted.')
    parser.add_argument('--data_file', default='plot_geno_fields.dat',
        help='''Name of the output data file. Each line consists of a sample name, a field name,
            followed by geno info of each variant, delimited by tabs.''')
    parser.add_argument('--samples', nargs='*',
        help='''Conditions based on which samples are selected. Default to all samples.''')
    parser.add_argument('--genotypes', nargs='*',
        help='''Conditions based on which genotypes are selected. Default to all variants.''') 
    hist = parser.add_argument_group('Draw histogram')
    hist.add_argument('--hist',
        help='''File name of the outputted figure, which can have type PDF,
            EPS, or JPG. Multiple files might be produced if more than one figure
            is produced (e.g. MyFig1.pdf, MyFig2.pdf if MyFig.pdf is specified).''')
    hist.add_argument('--title',
        help='''Title of the histogram. '$FIELD' in the title will be replaced
            by name of the field.''')
    #hist.add_argument('--group_by',
    #    help='''A field that will be used to group others. The histogram of this
    #        field will not be plotted.''')
    #
    #cust = parser.add_argument_group('Draw plot using user-specified script.')
    #cust.add_argument('--script', nargs='+', metavar=('SCRIPT', 'OPT'), 
    #    help='''Path to a user-provided script, which
    #        will be called by 'Rscript $script $name' where $name is the data file
    #        generated by this command. Additional arguments of this script will be passed
    #        directly the script.''')
    
def plotGenoFields(args):
    # step 1, get samples, there is no group so the for loop is not useful
    logger.info('Generating data file {}'.format(args.data_file))
    with open(args.data_file, 'w') as output:
        for g, IDs, names in getSamples(args.samples):
            for id, name in zip(IDs, names):
                output.write(name + '\t')
                for field in args.fields:
                    output.write(field)
                    values = getoutput(['vtools', 'execute',
                        'SELECT {} FROM genotype.genotype_{} {}'.format(field, id,
                            ('WHERE ' + ','.join(['({})' % x for x in args.genotypes])) if args.genotypes else '')])
                    for line in values.split('\n'):
                        output.write('\t' + line)
                    output.write('\n')
    if args.hist is not None:
        # Here we generate the data file (which can be big),
        # create a script dynamically, and pump it to a R process.
        #
        # note the use of {{, }} for real {}
        script=r'''
            # read data
            data <- c()
            con  <- file("{0.data_file}", open = "r")
            while (length(oneLine <- readLines(con, n = 1, warn = FALSE)) > 0) {{
                # split
                line_data = unlist(strsplit(oneLine, '\t'))
                # skip 2
                line_data = line_data[3:length(line_data)]
                # map to float
                data = c(data, sapply(line_data, as.double))
            }} 
            {1} # start device
            tryCatch( {{
                hist(data)
            }}, error = function(err) {{
                print(paste('Failed to generate histogram: ', err))
            }})
            dev.off()
            '''.format(args,
                RdeviceFromFilename(args.hist))
        # 
        # call the script
        executeRScript(script)

if __name__ == '__main__':
    #
    master_parser = argparse.ArgumentParser(description='''A collection of functions that
        analyze data using vtools and generate various reports''',
        prog='vtools_report',
        #formatter_class=argparse.RawDescriptionHelpFormatter,
        fromfile_prefix_chars='@',  
        epilog='''Use 'vtools_report cmd -h' for details about each command.
        Please contact Bo Peng (bpeng at mdanderson.org) if you have any question.''')
    master_parser.add_argument('--version', action='version', version='%(prog)s 1.0')
    subparsers = master_parser.add_subparsers(title='Available reports')
    #
    # command trans_ratio
    parser = subparsers.add_parser('trans_ratio',
        help='Transition count, transversion count and transition/transversion ratio',
        description='''This command counts the number of transition (A<->G and C<->T) and
            transversion variants (others) and calculate its ratio. A ratio of 2 is expected
            from a normal sample. If option '--by_count' is specified, it will calculate
            this ratio for variants with different sample allele frequency (count). This
            commands requires a field that stores the sample count for each variant, which
            should be prepared using command 'vtools update table --from_stat "num=#(alt)"'.''')
    transRatioArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=transRatio)
    #
    # command avg_depth
    parser = subparsers.add_parser('avg_depth',
        help='Average depth for each variant, can be divided by sample variant count',
        description='''Command 'vtools update table --from_stat "meanDP=avg(DP_geno)"' calculates the average
            depth of variants across sample (e.g. average depth of three variants if the 
            variant appears three times in the sample). This command report average depth
            of all variants, or variants divided by sample allele count (output count,
            number of variant, and average depth for count from 1 to 2*#sample). This
            command requires a field that stores the sample count for each variant and
            a field to store average depth of each variant, which should be prepared
            using command 'vtools update table --from_stat "num=#(alt)" "meanDP=avg(DP_geno)"'.''')
    avgDepthArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=avgDepth)
    #
    # command variant_stat
    parser = subparsers.add_parser('variant_stat',
        help='''Reports number of snps, insertions, deletions and substitutions for
            groups of samples with some size metrics to characterize the indels''',
        description='''Command 'vtools variant_stat' calculates the number of 
            snps, insertions, deletions and substitutions for groups of samples
            with some size metrics to characterize the indels. The statistics can
            be calculated for all samples (effectively for the master variant table
            when parameters --samples and --group_by are ignored), a subset of samples
            (e.g. --samples aff=1), grouped by samples (e.g. --group_by aff), or for
            each sample separately (e.g. --group_by filename sample_name, because those
            two fields in the sample table uniquely identify each sample.''')
    variantStatArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=variantStat)
    #
    # command discordance_rate
    parser = subparsers.add_parser('discordance_rate',
        help='''Report discordance rate, namely the number of genotype calls that differ
            between a pair of samples divided by the total number of SNPs for which both
            calls are non-missing, between pairs of samples. The statistics can be
            calculated for all samples or selected samples specified by parameter --samples.
            This command output a n by n matrix with sample names in the header. Items (i,j)
            in this matrix is numbers in the format of diff/all for i >= j, and the actual
            ratio for i < j. This rate is affected by runtime option treat_missing_as_wildtype
            which assumes that variants that do not appear in a sample (or filtered by
            quality score etc) are wildtype alleles.''')
    discordanceRateArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=discordanceRate)
    #
    # command plot_fields
    parser = subparsers.add_parser('plot_fields',
        help='''Dump values of specified variant info field(s) and/or annotation fields to
            a file and draw various plots. It essentially calls 'vtools output $table $fields',
            write output to a file, and utilizes R (www.r-project.org) to draw the plots. The
            script will be written to vtools_report.log which can be extracted and customied.''')
    plotFieldsArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=plotFields)
    #
    # command plot_fields
    parser = subparsers.add_parser('plot_geno_fields',
        help='''Dump values of specified genotype variant info field(s) of all or selected
            samples to a file and draw various plots using a R script. Each line of the data
            file starts with a sample name and a field name, followed by values of all
            variants. Because samples can have different number of variants, the data file
            does not have to have equal number of columns.''')
    plotGenoFieldsArguments(parser)
    addVerbosityArg(parser)
    parser.set_defaults(func=plotGenoFields)
    #
    # getting args
    args = master_parser.parse_args()
    # setting global logger
    verbosity = args.verbosity
    logger = getLogger()
    # calling the associated functions
    args.func(args)
